{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>M</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>B</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>B</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>M</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0   8670         M        15.46         19.48          101.70      748.9   \n",
       "1   8913         B        12.89         13.12           81.89      515.9   \n",
       "2   8915         B        14.96         19.10           97.03      687.3   \n",
       "3   9047         B        12.94         16.17           83.18      507.6   \n",
       "4  85715         M        13.17         18.66           85.98      534.6   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.10920           0.12230         0.14660              0.08087   \n",
       "1          0.06955           0.03729         0.02260              0.01171   \n",
       "2          0.08992           0.09823         0.05940              0.04819   \n",
       "3          0.09879           0.08836         0.03296              0.02390   \n",
       "4          0.11580           0.12310         0.12260              0.07340   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         19.26          26.00           124.90      1156.0   \n",
       "1  ...         13.62          15.54            87.40       577.0   \n",
       "2  ...         16.25          26.19           109.10       809.8   \n",
       "3  ...         13.86          23.02            89.69       580.9   \n",
       "4  ...         15.67          27.95           102.80       759.4   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.15460             0.2394           0.3791               0.15140   \n",
       "1           0.09616             0.1147           0.1186               0.05366   \n",
       "2           0.13130             0.3030           0.1804               0.14890   \n",
       "3           0.11720             0.1958           0.1810               0.08388   \n",
       "4           0.17860             0.4166           0.5006               0.20880   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.2837                  0.08019  \n",
       "1          0.2309                  0.06915  \n",
       "2          0.2962                  0.08472  \n",
       "3          0.3297                  0.07834  \n",
       "4          0.3900                  0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.read_csv(os.path.join(\"data.csv\"))\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.loc[(cancer_df.diagnosis == 'B'),'diagnosis']='Benign'\n",
    "cancer_df.loc[(cancer_df.diagnosis == 'M'),'diagnosis']='Malignant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.rename(columns = {'id':'Paitent ID', 'diagnosis':'Diagnosis'\n",
    "                            , 'radius_mean':'Radius (Mean)', 'texture_mean':'Texture (Mean)', 'perimeter_mean':'Perimeter (Mean)'\n",
    "                           , 'area_mean':'Area (Mean)', 'smoothness_mean':'Smoothness (Mean)', 'compactness_mean':'Compactness (Mean)', 'concavity_mean':'Concavity (Mean)', 'concave points_mean':'Concave Points (Mean)'\n",
    "                           , 'symmetry_mean':'Symmetry (Mean)', 'fractal_dimension_mean':'Fractal Dimension (Mean)'\n",
    "                            , 'radius_se':'Radius (Standard Error)', 'texture_se':'Texture (Standard Error)', 'perimeter_se':'Perimeter (Standard Error)'\n",
    "                            , 'area_se':'Area (Standard Error)', 'smoothness_se':'Smoothness (Standard Error)', 'compactness_se':'Compactness (Standard Error)', 'concavity_se':'Concavity (Standard Error)', 'concave points_se':'Concave Points (Standard Error)'\n",
    "                            , 'symmetry_se':'Symmetry (Standard Error)', 'fractal_dimension_se':'Fractal Dimension (Standard Error)'\n",
    "                            , 'radius_worst':'Radius (Worst)', 'texture_worst':'Texture (Worst)', 'perimeter_worst':'Perimeter (Worst)'\n",
    "                           , 'area_worst':'Area (Worst)', 'smoothness_worst':'Smoothness (Worst)', 'compactness_worst':'Compactness (Worst)', 'concavity_worst':'Concavity (Worst)', 'concave points_worst':'Concave Points (Worst)'\n",
    "                           , 'symmetry_worst':'Symmetry (Worst)', 'fractal_dimension_worst':'Fractal Dimension (Worst)'\n",
    "                           }, inplace = True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df.to_csv(r\"C:\\Users\\Magrathea\\Documents\\GIT_Hub\\Projects\\Final-Project\\Cancer_Data.csv\")\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31) (569,)\n"
     ]
    }
   ],
   "source": [
    "X = cancer_df.drop(\"Diagnosis\", axis=1)\n",
    "y = cancer_df[\"Diagnosis\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magrathea\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.40375586854460094\n",
      "Testing Data Score: 0.44755244755244755\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   ['Malignant' 'Malignant' 'Malignant' 'Malignant' 'Malignant' 'Malignant'\n",
      " 'Malignant' 'Malignant' 'Malignant' 'Malignant']\n",
      "First 10 Actual labels: ['Malignant', 'Malignant', 'Benign', 'Benign', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Benign', 'Benign']\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>Benign</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction     Actual\n",
       "0    Malignant  Malignant\n",
       "1    Malignant  Malignant\n",
       "2    Malignant     Benign\n",
       "3    Malignant     Benign\n",
       "4    Malignant     Benign\n",
       "..         ...        ...\n",
       "138  Malignant  Malignant\n",
       "139  Malignant     Benign\n",
       "140     Benign     Benign\n",
       "141  Malignant     Benign\n",
       "142  Malignant     Benign\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cancer_df[\"Diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>Symmetry (Mean)</th>\n",
       "      <th>Fractal Dimension (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.05852</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.06200</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.06777</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Radius (Mean)  Texture (Mean)  Perimeter (Mean)  Area (Mean)  \\\n",
       "0          15.46           19.48            101.70        748.9   \n",
       "1          12.89           13.12             81.89        515.9   \n",
       "2          14.96           19.10             97.03        687.3   \n",
       "3          12.94           16.17             83.18        507.6   \n",
       "4          13.17           18.66             85.98        534.6   \n",
       "\n",
       "   Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0            0.10920             0.12230           0.14660   \n",
       "1            0.06955             0.03729           0.02260   \n",
       "2            0.08992             0.09823           0.05940   \n",
       "3            0.09879             0.08836           0.03296   \n",
       "4            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  Symmetry (Mean)  Fractal Dimension (Mean)  ...  \\\n",
       "0                0.08087           0.1931                   0.05796  ...   \n",
       "1                0.01171           0.1337                   0.05581  ...   \n",
       "2                0.04819           0.1879                   0.05852  ...   \n",
       "3                0.02390           0.1735                   0.06200  ...   \n",
       "4                0.07340           0.2128                   0.06777  ...   \n",
       "\n",
       "   Radius (Worst)  Texture (Worst)  Perimeter (Worst)  Area (Worst)  \\\n",
       "0           19.26            26.00             124.90        1156.0   \n",
       "1           13.62            15.54              87.40         577.0   \n",
       "2           16.25            26.19             109.10         809.8   \n",
       "3           13.86            23.02              89.69         580.9   \n",
       "4           15.67            27.95             102.80         759.4   \n",
       "\n",
       "   Smoothness (Worst)  Compactness (Worst)  Concavity (Worst)  \\\n",
       "0             0.15460               0.2394             0.3791   \n",
       "1             0.09616               0.1147             0.1186   \n",
       "2             0.13130               0.3030             0.1804   \n",
       "3             0.11720               0.1958             0.1810   \n",
       "4             0.17860               0.4166             0.5006   \n",
       "\n",
       "   Concave Points (Worst)  Symmetry (Worst)  Fractal Dimension (Worst)  \n",
       "0                 0.15140            0.2837                    0.08019  \n",
       "1                 0.05366            0.2309                    0.06915  \n",
       "2                 0.14890            0.2962                    0.08472  \n",
       "3                 0.08388            0.3297                    0.07834  \n",
       "4                 0.20880            0.3900                    0.11790  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = cancer_df.drop(\"Diagnosis\", axis =1)\n",
    "X = X_df.drop(\"Paitent ID\", axis =1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.916\n",
      "k: 3, Train/Test Score: 0.958/0.923\n",
      "k: 5, Train/Test Score: 0.944/0.930\n",
      "k: 7, Train/Test Score: 0.944/0.916\n",
      "k: 9, Train/Test Score: 0.944/0.916\n",
      "k: 11, Train/Test Score: 0.946/0.923\n",
      "k: 13, Train/Test Score: 0.944/0.923\n",
      "k: 15, Train/Test Score: 0.937/0.930\n",
      "k: 17, Train/Test Score: 0.937/0.930\n",
      "k: 19, Train/Test Score: 0.937/0.930\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_score = knn.score(X_train, y_train)\n",
    "    test_score = knn.score(X_test, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=13 Test Acc: 0.923\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train, y_train)\n",
    "print('k=13 Test Acc: %.3f' % knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train_categorical)\n",
    "clf.score(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train_categorical)\n",
    "rf.score(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.15312667465468519, 'Concave Points (Worst)'),\n",
       " (0.1479748598750349, 'Perimeter (Worst)'),\n",
       " (0.12026465502396233, 'Radius (Worst)'),\n",
       " (0.11835143718180487, 'Area (Worst)'),\n",
       " (0.08297720087371702, 'Concave Points (Mean)'),\n",
       " (0.060099528128440244, 'Perimeter (Mean)'),\n",
       " (0.03702454177993685, 'Concavity (Mean)'),\n",
       " (0.036739949850905694, 'Radius (Mean)'),\n",
       " (0.03527325265250417, 'Area (Mean)'),\n",
       " (0.027694831055260116, 'Concavity (Worst)'),\n",
       " (0.026184308141644873, 'Area (Standard Error)'),\n",
       " (0.020906536663512915, 'Compactness (Worst)'),\n",
       " (0.013605004885376462, 'Texture (Mean)'),\n",
       " (0.013516804187162121, 'Smoothness (Worst)'),\n",
       " (0.011830053501529025, 'Perimeter (Standard Error)'),\n",
       " (0.011115112449965958, 'Texture (Worst)'),\n",
       " (0.010388074849254214, 'Symmetry (Worst)'),\n",
       " (0.010112755050202054, 'Compactness (Mean)'),\n",
       " (0.008193654468636364, 'Radius (Standard Error)'),\n",
       " (0.006618737928360616, 'Concave Points (Standard Error)'),\n",
       " (0.006358458357265047, 'Smoothness (Mean)'),\n",
       " (0.005648154707187333, 'Symmetry (Mean)'),\n",
       " (0.00559150300565547, 'Fractal Dimension (Worst)'),\n",
       " (0.005534635612098076, 'Fractal Dimension (Standard Error)'),\n",
       " (0.004873918403730025, 'Concavity (Standard Error)'),\n",
       " (0.004816093999741597, 'Smoothness (Standard Error)'),\n",
       " (0.00464513400045318, 'Compactness (Standard Error)'),\n",
       " (0.0038436313319156644, 'Symmetry (Standard Error)'),\n",
       " (0.0037539444027283146, 'Fractal Dimension (Mean)'),\n",
       " (0.002936552977329358, 'Texture (Standard Error)')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build lists for mean and SEM Value for radius and permiter values\n",
    "#Radius (Mean)\n",
    "radius_means = cancer_df.loc[:, ['Radius (Mean)']]\n",
    "radius_means = radius_means['Radius (Mean)']\n",
    "\n",
    "#Perimeter (Worst)\n",
    "perimeter_means = cancer_df.loc[:, ['Perimeter (Worst)']]\n",
    "perimeter_means = perimeter_means['Perimeter (Worst)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the Plot (with Error Bars)\n",
    "#Min/Max values for volume to determine limits on plot chart\n",
    "min_volume = cancer_df.min()['Radius (Mean)']\n",
    "max_volume = cancer_df.max()['Radius (Mean)']\n",
    "max_yvolume = cancer_df.max()['Perimeter (Worst)']\n",
    "\n",
    "#create additional white space on plot chart\n",
    "min_volume = min_volume - 1\n",
    "max_volume = max_volume + 1\n",
    "max_yvolume = max_yvolume + 2\n",
    "#Limits, background grid, title, labels\n",
    "plt.grid(True)\n",
    "\n",
    "plt.ylabel(\"Perimeter (Worst)\")\n",
    "plt.xlabel(\"Radius (Mean)\")\n",
    "plt.title(\"Perimeter v Radius\")\n",
    "plt.scatter(radius_means, perimeter_means)\n",
    "plt.legend(frameon=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      1.00      0.98        80\n",
      "    positive       1.00      0.94      0.97        63\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.98      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Magrathea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.923, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.937, total=   0.8s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.943, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.923, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.937, total=   0.8s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.943, total=   0.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.923, total=   0.5s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.937, total=   0.7s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.943, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.916, total=   0.8s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.937, total=   1.8s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.929, total=   4.6s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.916, total=   0.7s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.937, total=   1.7s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.929, total=   4.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.916, total=   0.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.937, total=   1.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ..................... C=5, gamma=0.01, score=0.929, total=   4.5s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.930, total=   0.7s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.937, total=   2.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.943, total=   2.7s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.930, total=   0.7s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.937, total=   1.9s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.943, total=   2.3s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.930, total=   0.7s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.937, total=   2.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.943, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   41.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='linear',\n",
       "                           max_iter=-1, probability=False, random_state=None,\n",
       "                           shrinking=True, tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9366197183098591\n"
     ]
    }
   ],
   "source": [
    "# List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        blue       0.96      1.00      0.98        80\n",
      "         red       1.00      0.95      0.98        63\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"blue\", \"red\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paitent ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Radius (Mean)</th>\n",
       "      <th>Texture (Mean)</th>\n",
       "      <th>Perimeter (Mean)</th>\n",
       "      <th>Area (Mean)</th>\n",
       "      <th>Smoothness (Mean)</th>\n",
       "      <th>Compactness (Mean)</th>\n",
       "      <th>Concavity (Mean)</th>\n",
       "      <th>Concave Points (Mean)</th>\n",
       "      <th>...</th>\n",
       "      <th>Radius (Worst)</th>\n",
       "      <th>Texture (Worst)</th>\n",
       "      <th>Perimeter (Worst)</th>\n",
       "      <th>Area (Worst)</th>\n",
       "      <th>Smoothness (Worst)</th>\n",
       "      <th>Compactness (Worst)</th>\n",
       "      <th>Concavity (Worst)</th>\n",
       "      <th>Concave Points (Worst)</th>\n",
       "      <th>Symmetry (Worst)</th>\n",
       "      <th>Fractal Dimension (Worst)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8670</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.15460</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8913</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>...</td>\n",
       "      <td>13.62</td>\n",
       "      <td>15.54</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8915</td>\n",
       "      <td>Benign</td>\n",
       "      <td>14.96</td>\n",
       "      <td>19.10</td>\n",
       "      <td>97.03</td>\n",
       "      <td>687.3</td>\n",
       "      <td>0.08992</td>\n",
       "      <td>0.09823</td>\n",
       "      <td>0.05940</td>\n",
       "      <td>0.04819</td>\n",
       "      <td>...</td>\n",
       "      <td>16.25</td>\n",
       "      <td>26.19</td>\n",
       "      <td>109.10</td>\n",
       "      <td>809.8</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.14890</td>\n",
       "      <td>0.2962</td>\n",
       "      <td>0.08472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9047</td>\n",
       "      <td>Benign</td>\n",
       "      <td>12.94</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "      <td>507.6</td>\n",
       "      <td>0.09879</td>\n",
       "      <td>0.08836</td>\n",
       "      <td>0.03296</td>\n",
       "      <td>0.02390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.86</td>\n",
       "      <td>23.02</td>\n",
       "      <td>89.69</td>\n",
       "      <td>580.9</td>\n",
       "      <td>0.11720</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>0.08388</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.07834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>85715</td>\n",
       "      <td>Malignant</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.66</td>\n",
       "      <td>85.98</td>\n",
       "      <td>534.6</td>\n",
       "      <td>0.11580</td>\n",
       "      <td>0.12310</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.07340</td>\n",
       "      <td>...</td>\n",
       "      <td>15.67</td>\n",
       "      <td>27.95</td>\n",
       "      <td>102.80</td>\n",
       "      <td>759.4</td>\n",
       "      <td>0.17860</td>\n",
       "      <td>0.4166</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.20880</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.11790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paitent ID  Diagnosis  Radius (Mean)  Texture (Mean)  Perimeter (Mean)  \\\n",
       "0        8670  Malignant          15.46           19.48            101.70   \n",
       "1        8913     Benign          12.89           13.12             81.89   \n",
       "2        8915     Benign          14.96           19.10             97.03   \n",
       "3        9047     Benign          12.94           16.17             83.18   \n",
       "4       85715  Malignant          13.17           18.66             85.98   \n",
       "\n",
       "   Area (Mean)  Smoothness (Mean)  Compactness (Mean)  Concavity (Mean)  \\\n",
       "0        748.9            0.10920             0.12230           0.14660   \n",
       "1        515.9            0.06955             0.03729           0.02260   \n",
       "2        687.3            0.08992             0.09823           0.05940   \n",
       "3        507.6            0.09879             0.08836           0.03296   \n",
       "4        534.6            0.11580             0.12310           0.12260   \n",
       "\n",
       "   Concave Points (Mean)  ...  Radius (Worst)  Texture (Worst)  \\\n",
       "0                0.08087  ...           19.26            26.00   \n",
       "1                0.01171  ...           13.62            15.54   \n",
       "2                0.04819  ...           16.25            26.19   \n",
       "3                0.02390  ...           13.86            23.02   \n",
       "4                0.07340  ...           15.67            27.95   \n",
       "\n",
       "   Perimeter (Worst)  Area (Worst)  Smoothness (Worst)  Compactness (Worst)  \\\n",
       "0             124.90        1156.0             0.15460               0.2394   \n",
       "1              87.40         577.0             0.09616               0.1147   \n",
       "2             109.10         809.8             0.13130               0.3030   \n",
       "3              89.69         580.9             0.11720               0.1958   \n",
       "4             102.80         759.4             0.17860               0.4166   \n",
       "\n",
       "   Concavity (Worst)  Concave Points (Worst)  Symmetry (Worst)  \\\n",
       "0             0.3791                 0.15140            0.2837   \n",
       "1             0.1186                 0.05366            0.2309   \n",
       "2             0.1804                 0.14890            0.2962   \n",
       "3             0.1810                 0.08388            0.3297   \n",
       "4             0.5006                 0.20880            0.3900   \n",
       "\n",
       "   Fractal Dimension (Worst)  \n",
       "0                    0.08019  \n",
       "1                    0.06915  \n",
       "2                    0.08472  \n",
       "3                    0.07834  \n",
       "4                    0.11790  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Reformat data\n",
    "data = cancer_df.values\n",
    "X = data[:, 2:35]\n",
    "y = data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_test)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Step 2: One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "number_inputs = 30\n",
    "number_hidden_nodes = 4\n",
    "model.add(Dense(units=number_hidden_nodes,\n",
    "                activation='relu', input_dim=number_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = 2\n",
    "model.add(Dense(units=6, activation='relu', input_dim=2))\n",
    "model.add(Dense(units=6, activation='relu'))\n",
    "model.add(Dense(units=number_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 124       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 30        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30)\n",
      "(426, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples\n",
      "Epoch 1/1000\n",
      "426/426 - 0s - loss: 0.7165 - accuracy: 0.3873\n",
      "Epoch 2/1000\n",
      "426/426 - 0s - loss: 0.6954 - accuracy: 0.5516\n",
      "Epoch 3/1000\n",
      "426/426 - 0s - loss: 0.6845 - accuracy: 0.6268\n",
      "Epoch 4/1000\n",
      "426/426 - 0s - loss: 0.6758 - accuracy: 0.6526\n",
      "Epoch 5/1000\n",
      "426/426 - 0s - loss: 0.6656 - accuracy: 0.6737\n",
      "Epoch 6/1000\n",
      "426/426 - 0s - loss: 0.6512 - accuracy: 0.7465\n",
      "Epoch 7/1000\n",
      "426/426 - 0s - loss: 0.6269 - accuracy: 0.8099\n",
      "Epoch 8/1000\n",
      "426/426 - 0s - loss: 0.5907 - accuracy: 0.8756\n",
      "Epoch 9/1000\n",
      "426/426 - 0s - loss: 0.5404 - accuracy: 0.9085\n",
      "Epoch 10/1000\n",
      "426/426 - 0s - loss: 0.4776 - accuracy: 0.9178\n",
      "Epoch 11/1000\n",
      "426/426 - 0s - loss: 0.4065 - accuracy: 0.9272\n",
      "Epoch 12/1000\n",
      "426/426 - 0s - loss: 0.3347 - accuracy: 0.9296\n",
      "Epoch 13/1000\n",
      "426/426 - 0s - loss: 0.2714 - accuracy: 0.9366\n",
      "Epoch 14/1000\n",
      "426/426 - 0s - loss: 0.2237 - accuracy: 0.9390\n",
      "Epoch 15/1000\n",
      "426/426 - 0s - loss: 0.1891 - accuracy: 0.9484\n",
      "Epoch 16/1000\n",
      "426/426 - 0s - loss: 0.1638 - accuracy: 0.9507\n",
      "Epoch 17/1000\n",
      "426/426 - 0s - loss: 0.1456 - accuracy: 0.9554\n",
      "Epoch 18/1000\n",
      "426/426 - 0s - loss: 0.1326 - accuracy: 0.9577\n",
      "Epoch 19/1000\n",
      "426/426 - 0s - loss: 0.1221 - accuracy: 0.9624\n",
      "Epoch 20/1000\n",
      "426/426 - 0s - loss: 0.1137 - accuracy: 0.9671\n",
      "Epoch 21/1000\n",
      "426/426 - 0s - loss: 0.1078 - accuracy: 0.9695\n",
      "Epoch 22/1000\n",
      "426/426 - 0s - loss: 0.1024 - accuracy: 0.9742\n",
      "Epoch 23/1000\n",
      "426/426 - 0s - loss: 0.0981 - accuracy: 0.9765\n",
      "Epoch 24/1000\n",
      "426/426 - 0s - loss: 0.0942 - accuracy: 0.9765\n",
      "Epoch 25/1000\n",
      "426/426 - 0s - loss: 0.0910 - accuracy: 0.9789\n",
      "Epoch 26/1000\n",
      "426/426 - 0s - loss: 0.0878 - accuracy: 0.9789\n",
      "Epoch 27/1000\n",
      "426/426 - 0s - loss: 0.0849 - accuracy: 0.9789\n",
      "Epoch 28/1000\n",
      "426/426 - 0s - loss: 0.0820 - accuracy: 0.9812\n",
      "Epoch 29/1000\n",
      "426/426 - 0s - loss: 0.0800 - accuracy: 0.9812\n",
      "Epoch 30/1000\n",
      "426/426 - 0s - loss: 0.0778 - accuracy: 0.9812\n",
      "Epoch 31/1000\n",
      "426/426 - 0s - loss: 0.0760 - accuracy: 0.9836\n",
      "Epoch 32/1000\n",
      "426/426 - 0s - loss: 0.0740 - accuracy: 0.9836\n",
      "Epoch 33/1000\n",
      "426/426 - 0s - loss: 0.0724 - accuracy: 0.9836\n",
      "Epoch 34/1000\n",
      "426/426 - 0s - loss: 0.0707 - accuracy: 0.9836\n",
      "Epoch 35/1000\n",
      "426/426 - 0s - loss: 0.0693 - accuracy: 0.9836\n",
      "Epoch 36/1000\n",
      "426/426 - 0s - loss: 0.0681 - accuracy: 0.9836\n",
      "Epoch 37/1000\n",
      "426/426 - 0s - loss: 0.0670 - accuracy: 0.9836\n",
      "Epoch 38/1000\n",
      "426/426 - 0s - loss: 0.0658 - accuracy: 0.9836\n",
      "Epoch 39/1000\n",
      "426/426 - 0s - loss: 0.0648 - accuracy: 0.9836\n",
      "Epoch 40/1000\n",
      "426/426 - 0s - loss: 0.0637 - accuracy: 0.9836\n",
      "Epoch 41/1000\n",
      "426/426 - 0s - loss: 0.0628 - accuracy: 0.9836\n",
      "Epoch 42/1000\n",
      "426/426 - 0s - loss: 0.0618 - accuracy: 0.9859\n",
      "Epoch 43/1000\n",
      "426/426 - 0s - loss: 0.0611 - accuracy: 0.9859\n",
      "Epoch 44/1000\n",
      "426/426 - 0s - loss: 0.0600 - accuracy: 0.9859\n",
      "Epoch 45/1000\n",
      "426/426 - 0s - loss: 0.0596 - accuracy: 0.9859\n",
      "Epoch 46/1000\n",
      "426/426 - 0s - loss: 0.0588 - accuracy: 0.9883\n",
      "Epoch 47/1000\n",
      "426/426 - 0s - loss: 0.0582 - accuracy: 0.9883\n",
      "Epoch 48/1000\n",
      "426/426 - 0s - loss: 0.0574 - accuracy: 0.9883\n",
      "Epoch 49/1000\n",
      "426/426 - 0s - loss: 0.0568 - accuracy: 0.9883\n",
      "Epoch 50/1000\n",
      "426/426 - 0s - loss: 0.0563 - accuracy: 0.9883\n",
      "Epoch 51/1000\n",
      "426/426 - 0s - loss: 0.0556 - accuracy: 0.9883\n",
      "Epoch 52/1000\n",
      "426/426 - 0s - loss: 0.0553 - accuracy: 0.9883\n",
      "Epoch 53/1000\n",
      "426/426 - 0s - loss: 0.0547 - accuracy: 0.9883\n",
      "Epoch 54/1000\n",
      "426/426 - 0s - loss: 0.0541 - accuracy: 0.9883\n",
      "Epoch 55/1000\n",
      "426/426 - 0s - loss: 0.0536 - accuracy: 0.9883\n",
      "Epoch 56/1000\n",
      "426/426 - 0s - loss: 0.0530 - accuracy: 0.9883\n",
      "Epoch 57/1000\n",
      "426/426 - 0s - loss: 0.0526 - accuracy: 0.9883\n",
      "Epoch 58/1000\n",
      "426/426 - 0s - loss: 0.0520 - accuracy: 0.9883\n",
      "Epoch 59/1000\n",
      "426/426 - 0s - loss: 0.0516 - accuracy: 0.9883\n",
      "Epoch 60/1000\n",
      "426/426 - 0s - loss: 0.0511 - accuracy: 0.9883\n",
      "Epoch 61/1000\n",
      "426/426 - 0s - loss: 0.0507 - accuracy: 0.9883\n",
      "Epoch 62/1000\n",
      "426/426 - 0s - loss: 0.0503 - accuracy: 0.9883\n",
      "Epoch 63/1000\n",
      "426/426 - 0s - loss: 0.0497 - accuracy: 0.9883\n",
      "Epoch 64/1000\n",
      "426/426 - 0s - loss: 0.0491 - accuracy: 0.9883\n",
      "Epoch 65/1000\n",
      "426/426 - 0s - loss: 0.0485 - accuracy: 0.9883\n",
      "Epoch 66/1000\n",
      "426/426 - 0s - loss: 0.0480 - accuracy: 0.9883\n",
      "Epoch 67/1000\n",
      "426/426 - 0s - loss: 0.0475 - accuracy: 0.9883\n",
      "Epoch 68/1000\n",
      "426/426 - 0s - loss: 0.0467 - accuracy: 0.9883\n",
      "Epoch 69/1000\n",
      "426/426 - 0s - loss: 0.0461 - accuracy: 0.9883\n",
      "Epoch 70/1000\n",
      "426/426 - 0s - loss: 0.0456 - accuracy: 0.9883\n",
      "Epoch 71/1000\n",
      "426/426 - 0s - loss: 0.0452 - accuracy: 0.9906\n",
      "Epoch 72/1000\n",
      "426/426 - 0s - loss: 0.0447 - accuracy: 0.9883\n",
      "Epoch 73/1000\n",
      "426/426 - 0s - loss: 0.0445 - accuracy: 0.9883\n",
      "Epoch 74/1000\n",
      "426/426 - 0s - loss: 0.0440 - accuracy: 0.9883\n",
      "Epoch 75/1000\n",
      "426/426 - 0s - loss: 0.0432 - accuracy: 0.9906\n",
      "Epoch 76/1000\n",
      "426/426 - 0s - loss: 0.0428 - accuracy: 0.9906\n",
      "Epoch 77/1000\n",
      "426/426 - 0s - loss: 0.0423 - accuracy: 0.9906\n",
      "Epoch 78/1000\n",
      "426/426 - 0s - loss: 0.0420 - accuracy: 0.9906\n",
      "Epoch 79/1000\n",
      "426/426 - 0s - loss: 0.0416 - accuracy: 0.9906\n",
      "Epoch 80/1000\n",
      "426/426 - 0s - loss: 0.0411 - accuracy: 0.9906\n",
      "Epoch 81/1000\n",
      "426/426 - 0s - loss: 0.0407 - accuracy: 0.9906\n",
      "Epoch 82/1000\n",
      "426/426 - 0s - loss: 0.0401 - accuracy: 0.9906\n",
      "Epoch 83/1000\n",
      "426/426 - 0s - loss: 0.0397 - accuracy: 0.9906\n",
      "Epoch 84/1000\n",
      "426/426 - 0s - loss: 0.0394 - accuracy: 0.9906\n",
      "Epoch 85/1000\n",
      "426/426 - 0s - loss: 0.0388 - accuracy: 0.9906\n",
      "Epoch 86/1000\n",
      "426/426 - 0s - loss: 0.0383 - accuracy: 0.9906\n",
      "Epoch 87/1000\n",
      "426/426 - 0s - loss: 0.0378 - accuracy: 0.9906\n",
      "Epoch 88/1000\n",
      "426/426 - 0s - loss: 0.0374 - accuracy: 0.9906\n",
      "Epoch 89/1000\n",
      "426/426 - 0s - loss: 0.0369 - accuracy: 0.9906\n",
      "Epoch 90/1000\n",
      "426/426 - 0s - loss: 0.0365 - accuracy: 0.9906\n",
      "Epoch 91/1000\n",
      "426/426 - 0s - loss: 0.0359 - accuracy: 0.9906\n",
      "Epoch 92/1000\n",
      "426/426 - 0s - loss: 0.0354 - accuracy: 0.9906\n",
      "Epoch 93/1000\n",
      "426/426 - 0s - loss: 0.0350 - accuracy: 0.9906\n",
      "Epoch 94/1000\n",
      "426/426 - 0s - loss: 0.0346 - accuracy: 0.9906\n",
      "Epoch 95/1000\n",
      "426/426 - 0s - loss: 0.0343 - accuracy: 0.9906\n",
      "Epoch 96/1000\n",
      "426/426 - 0s - loss: 0.0339 - accuracy: 0.9930\n",
      "Epoch 97/1000\n",
      "426/426 - 0s - loss: 0.0337 - accuracy: 0.9930\n",
      "Epoch 98/1000\n",
      "426/426 - 0s - loss: 0.0333 - accuracy: 0.9930\n",
      "Epoch 99/1000\n",
      "426/426 - 0s - loss: 0.0330 - accuracy: 0.9930\n",
      "Epoch 100/1000\n",
      "426/426 - 0s - loss: 0.0327 - accuracy: 0.9930\n",
      "Epoch 101/1000\n",
      "426/426 - 0s - loss: 0.0326 - accuracy: 0.9930\n",
      "Epoch 102/1000\n",
      "426/426 - 0s - loss: 0.0322 - accuracy: 0.9930\n",
      "Epoch 103/1000\n",
      "426/426 - 0s - loss: 0.0319 - accuracy: 0.9930\n",
      "Epoch 104/1000\n",
      "426/426 - 0s - loss: 0.0317 - accuracy: 0.9930\n",
      "Epoch 105/1000\n",
      "426/426 - 0s - loss: 0.0314 - accuracy: 0.9930\n",
      "Epoch 106/1000\n",
      "426/426 - 0s - loss: 0.0313 - accuracy: 0.9930\n",
      "Epoch 107/1000\n",
      "426/426 - 0s - loss: 0.0308 - accuracy: 0.9930\n",
      "Epoch 108/1000\n",
      "426/426 - 0s - loss: 0.0306 - accuracy: 0.9930\n",
      "Epoch 109/1000\n",
      "426/426 - 0s - loss: 0.0303 - accuracy: 0.9930\n",
      "Epoch 110/1000\n",
      "426/426 - 0s - loss: 0.0300 - accuracy: 0.9930\n",
      "Epoch 111/1000\n",
      "426/426 - 0s - loss: 0.0297 - accuracy: 0.9930\n",
      "Epoch 112/1000\n",
      "426/426 - 0s - loss: 0.0293 - accuracy: 0.9930\n",
      "Epoch 113/1000\n",
      "426/426 - 0s - loss: 0.0292 - accuracy: 0.9930\n",
      "Epoch 114/1000\n",
      "426/426 - 0s - loss: 0.0289 - accuracy: 0.9930\n",
      "Epoch 115/1000\n",
      "426/426 - 0s - loss: 0.0284 - accuracy: 0.9930\n",
      "Epoch 116/1000\n",
      "426/426 - 0s - loss: 0.0281 - accuracy: 0.9930\n",
      "Epoch 117/1000\n",
      "426/426 - 0s - loss: 0.0280 - accuracy: 0.9930\n",
      "Epoch 118/1000\n",
      "426/426 - 0s - loss: 0.0277 - accuracy: 0.9930\n",
      "Epoch 119/1000\n",
      "426/426 - 0s - loss: 0.0275 - accuracy: 0.9930\n",
      "Epoch 120/1000\n",
      "426/426 - 0s - loss: 0.0272 - accuracy: 0.9930\n",
      "Epoch 121/1000\n",
      "426/426 - 0s - loss: 0.0270 - accuracy: 0.9930\n",
      "Epoch 122/1000\n",
      "426/426 - 0s - loss: 0.0268 - accuracy: 0.9930\n",
      "Epoch 123/1000\n",
      "426/426 - 0s - loss: 0.0265 - accuracy: 0.9930\n",
      "Epoch 124/1000\n",
      "426/426 - 0s - loss: 0.0263 - accuracy: 0.9930\n",
      "Epoch 125/1000\n",
      "426/426 - 0s - loss: 0.0259 - accuracy: 0.9930\n",
      "Epoch 126/1000\n",
      "426/426 - 0s - loss: 0.0255 - accuracy: 0.9930\n",
      "Epoch 127/1000\n",
      "426/426 - 0s - loss: 0.0255 - accuracy: 0.9930\n",
      "Epoch 128/1000\n",
      "426/426 - 0s - loss: 0.0250 - accuracy: 0.9930\n",
      "Epoch 129/1000\n",
      "426/426 - 0s - loss: 0.0247 - accuracy: 0.9930\n",
      "Epoch 130/1000\n",
      "426/426 - 0s - loss: 0.0246 - accuracy: 0.9930\n",
      "Epoch 131/1000\n",
      "426/426 - 0s - loss: 0.0243 - accuracy: 0.9930\n",
      "Epoch 132/1000\n",
      "426/426 - 0s - loss: 0.0242 - accuracy: 0.9930\n",
      "Epoch 133/1000\n",
      "426/426 - 0s - loss: 0.0240 - accuracy: 0.9930\n",
      "Epoch 134/1000\n",
      "426/426 - 0s - loss: 0.0239 - accuracy: 0.9930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/1000\n",
      "426/426 - 0s - loss: 0.0237 - accuracy: 0.9930\n",
      "Epoch 136/1000\n",
      "426/426 - 0s - loss: 0.0235 - accuracy: 0.9930\n",
      "Epoch 137/1000\n",
      "426/426 - 0s - loss: 0.0234 - accuracy: 0.9930\n",
      "Epoch 138/1000\n",
      "426/426 - 0s - loss: 0.0232 - accuracy: 0.9930\n",
      "Epoch 139/1000\n",
      "426/426 - 0s - loss: 0.0231 - accuracy: 0.9930\n",
      "Epoch 140/1000\n",
      "426/426 - 0s - loss: 0.0230 - accuracy: 0.9930\n",
      "Epoch 141/1000\n",
      "426/426 - 0s - loss: 0.0229 - accuracy: 0.9930\n",
      "Epoch 142/1000\n",
      "426/426 - 0s - loss: 0.0227 - accuracy: 0.9930\n",
      "Epoch 143/1000\n",
      "426/426 - 0s - loss: 0.0226 - accuracy: 0.9930\n",
      "Epoch 144/1000\n",
      "426/426 - 0s - loss: 0.0225 - accuracy: 0.9930\n",
      "Epoch 145/1000\n",
      "426/426 - 0s - loss: 0.0224 - accuracy: 0.9930\n",
      "Epoch 146/1000\n",
      "426/426 - 0s - loss: 0.0223 - accuracy: 0.9930\n",
      "Epoch 147/1000\n",
      "426/426 - 0s - loss: 0.0224 - accuracy: 0.9930\n",
      "Epoch 148/1000\n",
      "426/426 - 0s - loss: 0.0220 - accuracy: 0.9930\n",
      "Epoch 149/1000\n",
      "426/426 - 0s - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 150/1000\n",
      "426/426 - 0s - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 151/1000\n",
      "426/426 - 0s - loss: 0.0219 - accuracy: 0.9930\n",
      "Epoch 152/1000\n",
      "426/426 - 0s - loss: 0.0216 - accuracy: 0.9930\n",
      "Epoch 153/1000\n",
      "426/426 - 0s - loss: 0.0214 - accuracy: 0.9930\n",
      "Epoch 154/1000\n",
      "426/426 - 0s - loss: 0.0213 - accuracy: 0.9930\n",
      "Epoch 155/1000\n",
      "426/426 - 0s - loss: 0.0212 - accuracy: 0.9930\n",
      "Epoch 156/1000\n",
      "426/426 - 0s - loss: 0.0211 - accuracy: 0.9930\n",
      "Epoch 157/1000\n",
      "426/426 - 0s - loss: 0.0209 - accuracy: 0.9930\n",
      "Epoch 158/1000\n",
      "426/426 - 0s - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 159/1000\n",
      "426/426 - 0s - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 160/1000\n",
      "426/426 - 0s - loss: 0.0206 - accuracy: 0.9930\n",
      "Epoch 161/1000\n",
      "426/426 - 0s - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 162/1000\n",
      "426/426 - 0s - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 163/1000\n",
      "426/426 - 0s - loss: 0.0203 - accuracy: 0.9930\n",
      "Epoch 164/1000\n",
      "426/426 - 0s - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 165/1000\n",
      "426/426 - 0s - loss: 0.0201 - accuracy: 0.9930\n",
      "Epoch 166/1000\n",
      "426/426 - 0s - loss: 0.0199 - accuracy: 0.9930\n",
      "Epoch 167/1000\n",
      "426/426 - 0s - loss: 0.0198 - accuracy: 0.9930\n",
      "Epoch 168/1000\n",
      "426/426 - 0s - loss: 0.0197 - accuracy: 0.9930\n",
      "Epoch 169/1000\n",
      "426/426 - 0s - loss: 0.0195 - accuracy: 0.9930\n",
      "Epoch 170/1000\n",
      "426/426 - 0s - loss: 0.0194 - accuracy: 0.9930\n",
      "Epoch 171/1000\n",
      "426/426 - 0s - loss: 0.0193 - accuracy: 0.9930\n",
      "Epoch 172/1000\n",
      "426/426 - 0s - loss: 0.0191 - accuracy: 0.9930\n",
      "Epoch 173/1000\n",
      "426/426 - 0s - loss: 0.0190 - accuracy: 0.9930\n",
      "Epoch 174/1000\n",
      "426/426 - 0s - loss: 0.0188 - accuracy: 0.9930\n",
      "Epoch 175/1000\n",
      "426/426 - 0s - loss: 0.0187 - accuracy: 0.9930\n",
      "Epoch 176/1000\n",
      "426/426 - 0s - loss: 0.0186 - accuracy: 0.9930\n",
      "Epoch 177/1000\n",
      "426/426 - 0s - loss: 0.0184 - accuracy: 0.9930\n",
      "Epoch 178/1000\n",
      "426/426 - 0s - loss: 0.0183 - accuracy: 0.9930\n",
      "Epoch 179/1000\n",
      "426/426 - 0s - loss: 0.0181 - accuracy: 0.9930\n",
      "Epoch 180/1000\n",
      "426/426 - 0s - loss: 0.0180 - accuracy: 0.9930\n",
      "Epoch 181/1000\n",
      "426/426 - 0s - loss: 0.0179 - accuracy: 0.9930\n",
      "Epoch 182/1000\n",
      "426/426 - 0s - loss: 0.0177 - accuracy: 0.9930\n",
      "Epoch 183/1000\n",
      "426/426 - 0s - loss: 0.0176 - accuracy: 0.9930\n",
      "Epoch 184/1000\n",
      "426/426 - 0s - loss: 0.0175 - accuracy: 0.9930\n",
      "Epoch 185/1000\n",
      "426/426 - 0s - loss: 0.0173 - accuracy: 0.9930\n",
      "Epoch 186/1000\n",
      "426/426 - 0s - loss: 0.0172 - accuracy: 0.9930\n",
      "Epoch 187/1000\n",
      "426/426 - 0s - loss: 0.0171 - accuracy: 0.9930\n",
      "Epoch 188/1000\n",
      "426/426 - 0s - loss: 0.0169 - accuracy: 0.9930\n",
      "Epoch 189/1000\n",
      "426/426 - 0s - loss: 0.0168 - accuracy: 0.9930\n",
      "Epoch 190/1000\n",
      "426/426 - 0s - loss: 0.0166 - accuracy: 0.9930\n",
      "Epoch 191/1000\n",
      "426/426 - 0s - loss: 0.0165 - accuracy: 0.9930\n",
      "Epoch 192/1000\n",
      "426/426 - 0s - loss: 0.0163 - accuracy: 0.9930\n",
      "Epoch 193/1000\n",
      "426/426 - 0s - loss: 0.0162 - accuracy: 0.9930\n",
      "Epoch 194/1000\n",
      "426/426 - 0s - loss: 0.0161 - accuracy: 0.9930\n",
      "Epoch 195/1000\n",
      "426/426 - 0s - loss: 0.0161 - accuracy: 0.9930\n",
      "Epoch 196/1000\n",
      "426/426 - 0s - loss: 0.0159 - accuracy: 0.9930\n",
      "Epoch 197/1000\n",
      "426/426 - 0s - loss: 0.0157 - accuracy: 0.9953\n",
      "Epoch 198/1000\n",
      "426/426 - 0s - loss: 0.0157 - accuracy: 0.9953\n",
      "Epoch 199/1000\n",
      "426/426 - 0s - loss: 0.0154 - accuracy: 0.9977\n",
      "Epoch 200/1000\n",
      "426/426 - 0s - loss: 0.0152 - accuracy: 0.9977\n",
      "Epoch 201/1000\n",
      "426/426 - 0s - loss: 0.0151 - accuracy: 0.9977\n",
      "Epoch 202/1000\n",
      "426/426 - 0s - loss: 0.0150 - accuracy: 0.9977\n",
      "Epoch 203/1000\n",
      "426/426 - 0s - loss: 0.0149 - accuracy: 0.9977\n",
      "Epoch 204/1000\n",
      "426/426 - 0s - loss: 0.0147 - accuracy: 0.9977\n",
      "Epoch 205/1000\n",
      "426/426 - 0s - loss: 0.0146 - accuracy: 0.9977\n",
      "Epoch 206/1000\n",
      "426/426 - 0s - loss: 0.0145 - accuracy: 0.9977\n",
      "Epoch 207/1000\n",
      "426/426 - 0s - loss: 0.0145 - accuracy: 0.9977\n",
      "Epoch 208/1000\n",
      "426/426 - 0s - loss: 0.0143 - accuracy: 0.9977\n",
      "Epoch 209/1000\n",
      "426/426 - 0s - loss: 0.0143 - accuracy: 0.9977\n",
      "Epoch 210/1000\n",
      "426/426 - 0s - loss: 0.0142 - accuracy: 0.9977\n",
      "Epoch 211/1000\n",
      "426/426 - 0s - loss: 0.0141 - accuracy: 0.9977\n",
      "Epoch 212/1000\n",
      "426/426 - 0s - loss: 0.0140 - accuracy: 0.9977\n",
      "Epoch 213/1000\n",
      "426/426 - 0s - loss: 0.0139 - accuracy: 0.9977\n",
      "Epoch 214/1000\n",
      "426/426 - 0s - loss: 0.0138 - accuracy: 0.9977\n",
      "Epoch 215/1000\n",
      "426/426 - 0s - loss: 0.0137 - accuracy: 0.9977\n",
      "Epoch 216/1000\n",
      "426/426 - 0s - loss: 0.0135 - accuracy: 0.9977\n",
      "Epoch 217/1000\n",
      "426/426 - 0s - loss: 0.0135 - accuracy: 0.9977\n",
      "Epoch 218/1000\n",
      "426/426 - 0s - loss: 0.0134 - accuracy: 0.9977\n",
      "Epoch 219/1000\n",
      "426/426 - 0s - loss: 0.0133 - accuracy: 0.9977\n",
      "Epoch 220/1000\n",
      "426/426 - 0s - loss: 0.0133 - accuracy: 0.9977\n",
      "Epoch 221/1000\n",
      "426/426 - 0s - loss: 0.0133 - accuracy: 0.9977\n",
      "Epoch 222/1000\n",
      "426/426 - 0s - loss: 0.0133 - accuracy: 0.9977\n",
      "Epoch 223/1000\n",
      "426/426 - 0s - loss: 0.0131 - accuracy: 0.9977\n",
      "Epoch 224/1000\n",
      "426/426 - 0s - loss: 0.0129 - accuracy: 0.9977\n",
      "Epoch 225/1000\n",
      "426/426 - 0s - loss: 0.0129 - accuracy: 0.9977\n",
      "Epoch 226/1000\n",
      "426/426 - 0s - loss: 0.0128 - accuracy: 0.9977\n",
      "Epoch 227/1000\n",
      "426/426 - 0s - loss: 0.0128 - accuracy: 0.9977\n",
      "Epoch 228/1000\n",
      "426/426 - 0s - loss: 0.0126 - accuracy: 0.9977\n",
      "Epoch 229/1000\n",
      "426/426 - 0s - loss: 0.0126 - accuracy: 0.9977\n",
      "Epoch 230/1000\n",
      "426/426 - 0s - loss: 0.0125 - accuracy: 0.9977\n",
      "Epoch 231/1000\n",
      "426/426 - 0s - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 232/1000\n",
      "426/426 - 0s - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 233/1000\n",
      "426/426 - 0s - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 234/1000\n",
      "426/426 - 0s - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 235/1000\n",
      "426/426 - 0s - loss: 0.0124 - accuracy: 0.9977\n",
      "Epoch 236/1000\n",
      "426/426 - 0s - loss: 0.0122 - accuracy: 0.9977\n",
      "Epoch 237/1000\n",
      "426/426 - 0s - loss: 0.0122 - accuracy: 0.9977\n",
      "Epoch 238/1000\n",
      "426/426 - 0s - loss: 0.0120 - accuracy: 0.9977\n",
      "Epoch 239/1000\n",
      "426/426 - 0s - loss: 0.0121 - accuracy: 0.9977\n",
      "Epoch 240/1000\n",
      "426/426 - 0s - loss: 0.0119 - accuracy: 0.9977\n",
      "Epoch 241/1000\n",
      "426/426 - 0s - loss: 0.0119 - accuracy: 0.9977\n",
      "Epoch 242/1000\n",
      "426/426 - 0s - loss: 0.0118 - accuracy: 0.9977\n",
      "Epoch 243/1000\n",
      "426/426 - 0s - loss: 0.0117 - accuracy: 0.9977\n",
      "Epoch 244/1000\n",
      "426/426 - 0s - loss: 0.0117 - accuracy: 0.9977\n",
      "Epoch 245/1000\n",
      "426/426 - 0s - loss: 0.0118 - accuracy: 0.9977\n",
      "Epoch 246/1000\n",
      "426/426 - 0s - loss: 0.0120 - accuracy: 0.9977\n",
      "Epoch 247/1000\n",
      "426/426 - 0s - loss: 0.0118 - accuracy: 0.9977\n",
      "Epoch 248/1000\n",
      "426/426 - 0s - loss: 0.0116 - accuracy: 0.9977\n",
      "Epoch 249/1000\n",
      "426/426 - 0s - loss: 0.0115 - accuracy: 0.9977\n",
      "Epoch 250/1000\n",
      "426/426 - 0s - loss: 0.0113 - accuracy: 0.9977\n",
      "Epoch 251/1000\n",
      "426/426 - 0s - loss: 0.0113 - accuracy: 0.9977\n",
      "Epoch 252/1000\n",
      "426/426 - 0s - loss: 0.0114 - accuracy: 0.9977\n",
      "Epoch 253/1000\n",
      "426/426 - 0s - loss: 0.0112 - accuracy: 0.9977\n",
      "Epoch 254/1000\n",
      "426/426 - 0s - loss: 0.0112 - accuracy: 0.9977\n",
      "Epoch 255/1000\n",
      "426/426 - 0s - loss: 0.0112 - accuracy: 0.9977\n",
      "Epoch 256/1000\n",
      "426/426 - 0s - loss: 0.0111 - accuracy: 0.9977\n",
      "Epoch 257/1000\n",
      "426/426 - 0s - loss: 0.0110 - accuracy: 0.9977\n",
      "Epoch 258/1000\n",
      "426/426 - 0s - loss: 0.0111 - accuracy: 0.9977\n",
      "Epoch 259/1000\n",
      "426/426 - 0s - loss: 0.0110 - accuracy: 0.9977\n",
      "Epoch 260/1000\n",
      "426/426 - 0s - loss: 0.0110 - accuracy: 0.9977\n",
      "Epoch 261/1000\n",
      "426/426 - 0s - loss: 0.0110 - accuracy: 0.9977\n",
      "Epoch 262/1000\n",
      "426/426 - 0s - loss: 0.0109 - accuracy: 0.9977\n",
      "Epoch 263/1000\n",
      "426/426 - 0s - loss: 0.0108 - accuracy: 0.9977\n",
      "Epoch 264/1000\n",
      "426/426 - 0s - loss: 0.0107 - accuracy: 0.9977\n",
      "Epoch 265/1000\n",
      "426/426 - 0s - loss: 0.0107 - accuracy: 0.9977\n",
      "Epoch 266/1000\n",
      "426/426 - 0s - loss: 0.0107 - accuracy: 0.9977\n",
      "Epoch 267/1000\n",
      "426/426 - 0s - loss: 0.0106 - accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268/1000\n",
      "426/426 - 0s - loss: 0.0108 - accuracy: 0.9977\n",
      "Epoch 269/1000\n",
      "426/426 - 0s - loss: 0.0107 - accuracy: 0.9977\n",
      "Epoch 270/1000\n",
      "426/426 - 0s - loss: 0.0107 - accuracy: 0.9977\n",
      "Epoch 271/1000\n",
      "426/426 - 0s - loss: 0.0107 - accuracy: 0.9977\n",
      "Epoch 272/1000\n",
      "426/426 - 0s - loss: 0.0106 - accuracy: 0.9977\n",
      "Epoch 273/1000\n",
      "426/426 - 0s - loss: 0.0106 - accuracy: 0.9977\n",
      "Epoch 274/1000\n",
      "426/426 - 0s - loss: 0.0104 - accuracy: 0.9977\n",
      "Epoch 275/1000\n",
      "426/426 - 0s - loss: 0.0105 - accuracy: 0.9977\n",
      "Epoch 276/1000\n",
      "426/426 - 0s - loss: 0.0103 - accuracy: 0.9977\n",
      "Epoch 277/1000\n",
      "426/426 - 0s - loss: 0.0103 - accuracy: 0.9977\n",
      "Epoch 278/1000\n",
      "426/426 - 0s - loss: 0.0103 - accuracy: 0.9977\n",
      "Epoch 279/1000\n",
      "426/426 - 0s - loss: 0.0102 - accuracy: 0.9977\n",
      "Epoch 280/1000\n",
      "426/426 - 0s - loss: 0.0102 - accuracy: 0.9977\n",
      "Epoch 281/1000\n",
      "426/426 - 0s - loss: 0.0101 - accuracy: 0.9977\n",
      "Epoch 282/1000\n",
      "426/426 - 0s - loss: 0.0102 - accuracy: 0.9977\n",
      "Epoch 283/1000\n",
      "426/426 - 0s - loss: 0.0101 - accuracy: 0.9977\n",
      "Epoch 284/1000\n",
      "426/426 - 0s - loss: 0.0101 - accuracy: 0.9977\n",
      "Epoch 285/1000\n",
      "426/426 - 0s - loss: 0.0102 - accuracy: 0.9977\n",
      "Epoch 286/1000\n",
      "426/426 - 0s - loss: 0.0100 - accuracy: 0.9977\n",
      "Epoch 287/1000\n",
      "426/426 - 0s - loss: 0.0100 - accuracy: 0.9977\n",
      "Epoch 288/1000\n",
      "426/426 - 0s - loss: 0.0100 - accuracy: 0.9977\n",
      "Epoch 289/1000\n",
      "426/426 - 0s - loss: 0.0099 - accuracy: 0.9977\n",
      "Epoch 290/1000\n",
      "426/426 - 0s - loss: 0.0097 - accuracy: 0.9977\n",
      "Epoch 291/1000\n",
      "426/426 - 0s - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 292/1000\n",
      "426/426 - 0s - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 293/1000\n",
      "426/426 - 0s - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 294/1000\n",
      "426/426 - 0s - loss: 0.0097 - accuracy: 0.9977\n",
      "Epoch 295/1000\n",
      "426/426 - 0s - loss: 0.0096 - accuracy: 0.9977\n",
      "Epoch 296/1000\n",
      "426/426 - 0s - loss: 0.0098 - accuracy: 0.9977\n",
      "Epoch 297/1000\n",
      "426/426 - 0s - loss: 0.0097 - accuracy: 0.9977\n",
      "Epoch 298/1000\n",
      "426/426 - 0s - loss: 0.0096 - accuracy: 0.9977\n",
      "Epoch 299/1000\n",
      "426/426 - 0s - loss: 0.0095 - accuracy: 0.9977\n",
      "Epoch 300/1000\n",
      "426/426 - 0s - loss: 0.0095 - accuracy: 0.9977\n",
      "Epoch 301/1000\n",
      "426/426 - 0s - loss: 0.0096 - accuracy: 0.9977\n",
      "Epoch 302/1000\n",
      "426/426 - 0s - loss: 0.0095 - accuracy: 0.9977\n",
      "Epoch 303/1000\n",
      "426/426 - 0s - loss: 0.0095 - accuracy: 0.9977\n",
      "Epoch 304/1000\n",
      "426/426 - 0s - loss: 0.0094 - accuracy: 0.9977\n",
      "Epoch 305/1000\n",
      "426/426 - 0s - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 306/1000\n",
      "426/426 - 0s - loss: 0.0094 - accuracy: 0.9977\n",
      "Epoch 307/1000\n",
      "426/426 - 0s - loss: 0.0094 - accuracy: 0.9977\n",
      "Epoch 308/1000\n",
      "426/426 - 0s - loss: 0.0094 - accuracy: 0.9977\n",
      "Epoch 309/1000\n",
      "426/426 - 0s - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 310/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 311/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 312/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 313/1000\n",
      "426/426 - 0s - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 314/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 315/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 316/1000\n",
      "426/426 - 0s - loss: 0.0092 - accuracy: 0.9977\n",
      "Epoch 317/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 318/1000\n",
      "426/426 - 0s - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 319/1000\n",
      "426/426 - 0s - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 320/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 321/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 322/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 323/1000\n",
      "426/426 - 0s - loss: 0.0090 - accuracy: 0.9977\n",
      "Epoch 324/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 325/1000\n",
      "426/426 - 0s - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 326/1000\n",
      "426/426 - 0s - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 327/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 328/1000\n",
      "426/426 - 0s - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 329/1000\n",
      "426/426 - 0s - loss: 0.0089 - accuracy: 0.9977\n",
      "Epoch 330/1000\n",
      "426/426 - 0s - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 331/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 332/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 333/1000\n",
      "426/426 - 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 334/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 335/1000\n",
      "426/426 - 0s - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 336/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 337/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 338/1000\n",
      "426/426 - 0s - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 339/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 340/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 341/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 342/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 343/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 344/1000\n",
      "426/426 - 0s - loss: 0.0085 - accuracy: 0.9977\n",
      "Epoch 345/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 346/1000\n",
      "426/426 - 0s - loss: 0.0087 - accuracy: 0.9977\n",
      "Epoch 347/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 348/1000\n",
      "426/426 - 0s - loss: 0.0086 - accuracy: 0.9977\n",
      "Epoch 349/1000\n",
      "426/426 - 0s - loss: 0.0085 - accuracy: 0.9977\n",
      "Epoch 350/1000\n",
      "426/426 - 0s - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 351/1000\n",
      "426/426 - 0s - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 352/1000\n",
      "426/426 - 0s - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 353/1000\n",
      "426/426 - 0s - loss: 0.0083 - accuracy: 0.9977\n",
      "Epoch 354/1000\n",
      "426/426 - 0s - loss: 0.0082 - accuracy: 0.9977\n",
      "Epoch 355/1000\n",
      "426/426 - 0s - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 356/1000\n",
      "426/426 - 0s - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 357/1000\n",
      "426/426 - 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 358/1000\n",
      "426/426 - 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 359/1000\n",
      "426/426 - 0s - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 360/1000\n",
      "426/426 - 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 361/1000\n",
      "426/426 - 0s - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 362/1000\n",
      "426/426 - 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 363/1000\n",
      "426/426 - 0s - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 364/1000\n",
      "426/426 - 0s - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 365/1000\n",
      "426/426 - 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 366/1000\n",
      "426/426 - 0s - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 367/1000\n",
      "426/426 - 0s - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 368/1000\n",
      "426/426 - 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 369/1000\n",
      "426/426 - 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 370/1000\n",
      "426/426 - 0s - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 371/1000\n",
      "426/426 - 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 372/1000\n",
      "426/426 - 0s - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 373/1000\n",
      "426/426 - 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 374/1000\n",
      "426/426 - 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 375/1000\n",
      "426/426 - 0s - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 376/1000\n",
      "426/426 - 0s - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 377/1000\n",
      "426/426 - 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 378/1000\n",
      "426/426 - 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 379/1000\n",
      "426/426 - 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 380/1000\n",
      "426/426 - 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 381/1000\n",
      "426/426 - 0s - loss: 0.0071 - accuracy: 0.9977\n",
      "Epoch 382/1000\n",
      "426/426 - 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 383/1000\n",
      "426/426 - 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 384/1000\n",
      "426/426 - 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 385/1000\n",
      "426/426 - 0s - loss: 0.0068 - accuracy: 0.9977\n",
      "Epoch 386/1000\n",
      "426/426 - 0s - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 387/1000\n",
      "426/426 - 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 388/1000\n",
      "426/426 - 0s - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 389/1000\n",
      "426/426 - 0s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 390/1000\n",
      "426/426 - 0s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 391/1000\n",
      "426/426 - 0s - loss: 0.0065 - accuracy: 0.9977\n",
      "Epoch 392/1000\n",
      "426/426 - 0s - loss: 0.0065 - accuracy: 0.9977\n",
      "Epoch 393/1000\n",
      "426/426 - 0s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 394/1000\n",
      "426/426 - 0s - loss: 0.0068 - accuracy: 0.9977\n",
      "Epoch 395/1000\n",
      "426/426 - 0s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 396/1000\n",
      "426/426 - 0s - loss: 0.0065 - accuracy: 0.9977\n",
      "Epoch 397/1000\n",
      "426/426 - 0s - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 398/1000\n",
      "426/426 - 0s - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 399/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 400/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/1000\n",
      "426/426 - 0s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 402/1000\n",
      "426/426 - 0s - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 403/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 404/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 405/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 406/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 407/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 408/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 409/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 410/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 411/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 412/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 413/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 414/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 415/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 416/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 417/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 418/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 419/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 420/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 421/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 422/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 423/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 424/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 425/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 426/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 427/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 428/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 429/1000\n",
      "426/426 - 0s - loss: 0.0060 - accuracy: 0.9977\n",
      "Epoch 430/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 431/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 432/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 433/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 434/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 435/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 436/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 437/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 438/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 439/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 440/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 441/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 442/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 443/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 444/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 445/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 446/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 447/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 448/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 449/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 450/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 451/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 452/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 453/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 454/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 455/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 456/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 457/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 458/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 459/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 460/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 461/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 462/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 463/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 464/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 465/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 466/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 467/1000\n",
      "426/426 - 0s - loss: 0.0059 - accuracy: 0.9977\n",
      "Epoch 468/1000\n",
      "426/426 - 0s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 469/1000\n",
      "426/426 - 0s - loss: 0.0063 - accuracy: 0.9977\n",
      "Epoch 470/1000\n",
      "426/426 - 0s - loss: 0.0066 - accuracy: 0.9977\n",
      "Epoch 471/1000\n",
      "426/426 - 0s - loss: 0.0062 - accuracy: 0.9977\n",
      "Epoch 472/1000\n",
      "426/426 - 0s - loss: 0.0061 - accuracy: 0.9977\n",
      "Epoch 473/1000\n",
      "426/426 - 0s - loss: 0.0058 - accuracy: 0.9977\n",
      "Epoch 474/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 475/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 476/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 477/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 478/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 479/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 480/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 481/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 482/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 483/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 484/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 485/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 486/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 487/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 488/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 489/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 490/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 491/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 492/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 493/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 494/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 495/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 496/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 497/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 498/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 499/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 500/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 501/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 502/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 503/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 504/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 505/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 506/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 507/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 508/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 509/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 510/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 511/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 512/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 513/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 514/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 515/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 516/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 517/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 518/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 519/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 520/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 521/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 522/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 523/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 524/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 525/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 526/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 527/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 528/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 529/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 530/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 531/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 532/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 533/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 534/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 535/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 536/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 537/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 538/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 539/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 540/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 541/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 542/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 543/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 544/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 545/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 546/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 547/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 548/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 549/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 550/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 551/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 552/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 553/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 554/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 555/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 556/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 557/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 558/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 559/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 560/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 561/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 562/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 563/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 564/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 565/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 566/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 567/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 568/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 569/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 570/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 571/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 572/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 573/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 574/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 575/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 576/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 577/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 578/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 579/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 580/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 581/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 582/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 583/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 584/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 585/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 586/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 587/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 588/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 589/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 590/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 591/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 592/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 593/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 594/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 595/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 596/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 597/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 598/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 599/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 600/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 601/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 602/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 603/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 604/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 605/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 606/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 607/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 608/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 609/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 610/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 611/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 612/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 613/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 614/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 615/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 616/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 617/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 618/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 619/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 620/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 621/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 622/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 623/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 624/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 625/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 626/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 627/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 628/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 629/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 630/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 631/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 632/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 633/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 634/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 635/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 636/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 637/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 638/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 639/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 640/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 641/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 642/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 643/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 644/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 645/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 646/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 647/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 648/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 649/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 650/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 651/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 652/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 653/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 654/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 655/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 656/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 657/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 658/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 659/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 660/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 661/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 662/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 663/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 664/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 665/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 666/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 668/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 669/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 670/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 671/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 672/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 673/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 674/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 675/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 676/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 677/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 678/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 679/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 680/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 681/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 682/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 683/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 684/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 685/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 686/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 687/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 688/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 689/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 690/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 691/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 692/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 693/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 694/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 695/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 696/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 697/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 698/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 699/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 700/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 701/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 702/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 703/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 704/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 705/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 706/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 707/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 708/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 709/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 710/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 711/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 712/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 713/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 714/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 715/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 716/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 717/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 718/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 719/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 720/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 721/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 722/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 723/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 724/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 725/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 726/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 727/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 728/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 729/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 730/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 731/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 732/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 733/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 734/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 735/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 736/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 737/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 738/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 739/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 740/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 741/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 742/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 743/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 744/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 745/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 746/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 747/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 748/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 749/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 750/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 751/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 752/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 753/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 754/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 755/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 756/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 757/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 758/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 759/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 760/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 761/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 762/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 763/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 764/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 765/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 766/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 767/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 768/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 769/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 770/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 771/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 772/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 773/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 774/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 775/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 776/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 777/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 778/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 779/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 780/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 781/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 782/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 783/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 784/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 785/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 786/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 787/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 788/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 789/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 790/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 791/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 792/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 793/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 794/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 795/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 796/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 797/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 798/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 799/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 801/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 802/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 803/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 804/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 805/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 806/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 807/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 808/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 809/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 810/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 811/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 812/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 813/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 814/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 815/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 816/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 817/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 818/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 819/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 820/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 821/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 822/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 823/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 824/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 825/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 826/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 827/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 828/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 829/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 830/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 831/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 832/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 833/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 834/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 835/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 836/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 837/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 838/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 839/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 840/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 841/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 842/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 843/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 844/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 845/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 846/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 847/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 848/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 849/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 850/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 851/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 852/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 853/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 854/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 855/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 856/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 857/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 858/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 859/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 860/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 861/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 862/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 863/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 864/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 865/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 866/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 867/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 868/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 869/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 870/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 871/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 872/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 873/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 874/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 875/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 876/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 877/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 878/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 879/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 880/1000\n",
      "426/426 - 0s - loss: 0.0057 - accuracy: 0.9977\n",
      "Epoch 881/1000\n",
      "426/426 - 0s - loss: 0.0056 - accuracy: 0.9977\n",
      "Epoch 882/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 883/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 884/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 885/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 886/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 887/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 888/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 889/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 890/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 891/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 892/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 893/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 894/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 895/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 896/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 897/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 898/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 899/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 900/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 901/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 902/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 903/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 904/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 905/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 906/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 907/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 908/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 909/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 910/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 911/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 912/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 913/1000\n",
      "426/426 - 0s - loss: 0.0055 - accuracy: 0.9977\n",
      "Epoch 914/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 915/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 916/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 917/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 918/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 919/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 920/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 921/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 922/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 923/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 924/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 925/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 926/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 927/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 928/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 929/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 930/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 931/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 932/1000\n",
      "426/426 - 0s - loss: 0.0052 - accuracy: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 933/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 934/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 935/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 936/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 937/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 938/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 939/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 940/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 941/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 942/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 943/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 944/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 945/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 946/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 947/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 948/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 949/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 950/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 951/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 952/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 953/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 954/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 955/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 956/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 957/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 958/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 959/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 960/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 961/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 962/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 963/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 964/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 965/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 966/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 967/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 968/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 969/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 970/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 971/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 972/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 973/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 974/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 975/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 976/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 977/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 978/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 979/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 980/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 981/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 982/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 983/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 984/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 985/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 986/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 987/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 988/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 989/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 990/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 991/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 992/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 993/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 994/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 995/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 996/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 997/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 998/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n",
      "Epoch 999/1000\n",
      "426/426 - 0s - loss: 0.0054 - accuracy: 0.9977\n",
      "Epoch 1000/1000\n",
      "426/426 - 0s - loss: 0.0053 - accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x150aad751c8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 - 0s - loss: 0.7703 - accuracy: 0.9580\n",
      "Loss: 0.7703354717130279, Accuracy: 0.9580419659614563\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the testing data\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
